{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3039736",
   "metadata": {},
   "source": [
    "# NER Tagger\n",
    "\n",
    "Named Entity Recognition (NER) , also known as entity chunking/extraction , is a popular technique used in information extraction to identify and segment the named entities and classify or categorize them under various predefined classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e455dd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/syedhadi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/syedhadi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn_crfsuite import CRF, scorers, metrics\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn_crfsuite import metrics as crf_metrics\n",
    "import scipy.stats\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aab8c2",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset an extract from GMB corpus which is tagged, annotated and built specifically to train the classifier to predict named entities such as name, location, etc. GMB is a fairly large corpus with a lot of annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f85233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1048565</th>\n",
       "      <th>1048566</th>\n",
       "      <th>1048567</th>\n",
       "      <th>1048568</th>\n",
       "      <th>1048569</th>\n",
       "      <th>1048570</th>\n",
       "      <th>1048571</th>\n",
       "      <th>1048572</th>\n",
       "      <th>1048573</th>\n",
       "      <th>1048574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence #</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>through</td>\n",
       "      <td>London</td>\n",
       "      <td>to</td>\n",
       "      <td>protest</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>impact</td>\n",
       "      <td>.</td>\n",
       "      <td>Indian</td>\n",
       "      <td>forces</td>\n",
       "      <td>said</td>\n",
       "      <td>they</td>\n",
       "      <td>responded</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>TO</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1048575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       1              2       3        4        5        \\\n",
       "Sentence #  Sentence: 1     NaN            NaN     NaN      NaN      NaN   \n",
       "Word          Thousands      of  demonstrators    have  marched  through   \n",
       "POS                 NNS      IN            NNS     VBP      VBN       IN   \n",
       "Tag                   O       O              O       O        O        O   \n",
       "\n",
       "           6       7        8       9        ... 1048565 1048566  \\\n",
       "Sentence #     NaN     NaN      NaN     NaN  ...     NaN     NaN   \n",
       "Word        London      to  protest     the  ...  impact       .   \n",
       "POS            NNP      TO       VB      DT  ...      NN       .   \n",
       "Tag          B-geo       O        O       O  ...       O       O   \n",
       "\n",
       "                    1048567 1048568 1048569 1048570    1048571 1048572  \\\n",
       "Sentence #  Sentence: 47959     NaN     NaN     NaN        NaN     NaN   \n",
       "Word                 Indian  forces    said    they  responded      to   \n",
       "POS                      JJ     NNS     VBD     PRP        VBD      TO   \n",
       "Tag                   B-gpe       O       O       O          O       O   \n",
       "\n",
       "           1048573 1048574  \n",
       "Sentence #     NaN     NaN  \n",
       "Word           the  attack  \n",
       "POS             DT      NN  \n",
       "Tag              O       O  \n",
       "\n",
       "[4 rows x 1048575 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading dataset\n",
    "\n",
    "\n",
    "#remove these comments below if SSL verification fails. (it sometimes fails if using MASON network)\n",
    "#import ssl\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2008%20-%20Project%206%20-%20Build%20your%20NER%20Tagger/ner_dataset.csv.gz', compression='gzip', encoding='ISO-8859-1')\n",
    "df.T #it is easier to understand the data when we see the transpose \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60cd8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1048565</th>\n",
       "      <th>1048566</th>\n",
       "      <th>1048567</th>\n",
       "      <th>1048568</th>\n",
       "      <th>1048569</th>\n",
       "      <th>1048570</th>\n",
       "      <th>1048571</th>\n",
       "      <th>1048572</th>\n",
       "      <th>1048573</th>\n",
       "      <th>1048574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence #</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>through</td>\n",
       "      <td>London</td>\n",
       "      <td>to</td>\n",
       "      <td>protest</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>impact</td>\n",
       "      <td>.</td>\n",
       "      <td>Indian</td>\n",
       "      <td>forces</td>\n",
       "      <td>said</td>\n",
       "      <td>they</td>\n",
       "      <td>responded</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>TO</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1048575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1              2            3            4        \\\n",
       "Sentence #  Sentence: 1  Sentence: 1    Sentence: 1  Sentence: 1  Sentence: 1   \n",
       "Word          Thousands           of  demonstrators         have      marched   \n",
       "POS                 NNS           IN            NNS          VBP          VBN   \n",
       "Tag                   O            O              O            O            O   \n",
       "\n",
       "                5            6            7            8            9        \\\n",
       "Sentence #  Sentence: 1  Sentence: 1  Sentence: 1  Sentence: 1  Sentence: 1   \n",
       "Word            through       London           to      protest          the   \n",
       "POS                  IN          NNP           TO           VB           DT   \n",
       "Tag                   O        B-geo            O            O            O   \n",
       "\n",
       "            ...          1048565          1048566          1048567  \\\n",
       "Sentence #  ...  Sentence: 47958  Sentence: 47958  Sentence: 47959   \n",
       "Word        ...           impact                .           Indian   \n",
       "POS         ...               NN                .               JJ   \n",
       "Tag         ...                O                O            B-gpe   \n",
       "\n",
       "                    1048568          1048569          1048570  \\\n",
       "Sentence #  Sentence: 47959  Sentence: 47959  Sentence: 47959   \n",
       "Word                 forces             said             they   \n",
       "POS                     NNS              VBD              PRP   \n",
       "Tag                       O                O                O   \n",
       "\n",
       "                    1048571          1048572          1048573          1048574  \n",
       "Sentence #  Sentence: 47959  Sentence: 47959  Sentence: 47959  Sentence: 47959  \n",
       "Word              responded               to              the           attack  \n",
       "POS                     VBD               TO               DT               NN  \n",
       "Tag                       O                O                O                O  \n",
       "\n",
       "[4 rows x 1048575 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "We can handle NaN values by using the 'pandas.DataFrame.ffill' function. It replaces NaN values with values from \n",
    "the previous row. \n",
    "\n",
    "This is an informed decision. Because currently we have a sparse dataset where the Sentence # is populated only for \n",
    "the first word of the sentence. This function puts the relevant sentence number against each word of each sentence. \n",
    "This allows us to group sentences together much easier. \n",
    "'''\n",
    "\n",
    "df = df.fillna(method='ffill')\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6a51dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique sentences, # of unique words, # of unique POS tags, # of unique NER tags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(47959, 35178, 42, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('# of unique sentences, # of unique words, # of unique POS tags, # of unique NER tags')\n",
    "df['Sentence #'].nunique(), df.Word.nunique(), df.POS.nunique(), df.Tag.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98449b3",
   "metadata": {},
   "source": [
    "### NER Tags\n",
    "\n",
    "The tags in this dataset are explained as follows:\n",
    "\n",
    "1. geo = Geographical Entity\n",
    "2. org = Organization\n",
    "3. per = Person\n",
    "4. gpe = Geopolitical Entity\n",
    "5. tim = Time indicator\n",
    "6. art = Artifact\n",
    "7. eve = Event\n",
    "8. nat = Natural Phenomenon\n",
    "\n",
    "\n",
    "Anything outside these classes is termed as other, denoted as O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09483d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Distribution of Tags\n",
    "df.Tag.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3fa335",
   "metadata": {},
   "source": [
    "### Transforming the Dataset\n",
    "\n",
    "Our dataset is built of words, POS tags and NER tags. However, we need to transform it into complete sentences\n",
    "before we can train a model for NER tagging. This is because the position of a word within a sentence is important\n",
    "for NER tagging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d8163b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #           Word  POS Tag\n",
       "0            Sentence: 1      Thousands  NNS   O\n",
       "1            Sentence: 1             of   IN   O\n",
       "2            Sentence: 1  demonstrators  NNS   O\n",
       "3            Sentence: 1           have  VBP   O\n",
       "4            Sentence: 1        marched  VBN   O\n",
       "...                  ...            ...  ...  ..\n",
       "1048570  Sentence: 47959           they  PRP   O\n",
       "1048571  Sentence: 47959      responded  VBD   O\n",
       "1048572  Sentence: 47959             to   TO   O\n",
       "1048573  Sentence: 47959            the   DT   O\n",
       "1048574  Sentence: 47959         attack   NN   O\n",
       "\n",
       "[1048575 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80eb9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A class to retrieve the sentences from the dataset. Group by the attribute Sentence# and create 1 observation for\n",
    "each sentence. \n",
    "\n",
    "'''\n",
    "\n",
    "class getsentence(object):    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1.0\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb350cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "getter = getsentence(df)\n",
    "sentences = getter.sentences\n",
    "#This is how a sentence (one observation) will look like in the dataset. \n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a11be54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47959"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Sentences in the (transformed) dataset\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932b62f",
   "metadata": {},
   "source": [
    "## Conditional Random Field (CRF) Classifier\n",
    "\n",
    "A Conditional Random Field (CRF) is a standard model for predicting the most likely sequence of labels that correspond to a sequence of inputs. It is a supervised learning method which has been proven to be better than the tree based models when it comes to NER. Whereas a discrete classifier predicts a label for a single sample without considering \"neighboring\" samples, a CRF can take context into account; e.g., the linear chain CRF (which is popular in natural language processing) predicts sequences of labels for sequences of input samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfef445",
   "metadata": {},
   "source": [
    "### Feature Generation\n",
    "\n",
    "\n",
    "In order to use CRF, we will enhance the feature set and create more features which can be used by the model to predict the tags correctly. Since we need to take into account the context as well, we create features which will provide consecutive POS tags for each word. Also, we add new features such as upper, lower, digit, title etc. for each word and also consider the consecutive words in the list. In short, we try to provide a sequence of features to the model for each word - the sequence containing POS tags, capitalisations, type of word(title) etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8948d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A sentence and an index for a word within the sentence are passed as inputs. \n",
    "The output is a dictionary of features that contains information for the current, previous and next word. \n",
    "\n",
    "Sample Input: ('demonstrators', 'NNS', 'O')\n",
    "\n",
    "Previous Word: ('of', 'IN', 'O')\n",
    "\n",
    "Next Word: ('have', 'VBP', 'O')\n",
    "\n",
    "Sample Output (Features generated by the function)\n",
    "{'bias': 1.0,\n",
    " 'word.lower()': 'demonstrators',\n",
    " 'word[-3:]': 'ors',\n",
    " 'word[-2:]': 'rs',\n",
    " 'word.isupper()': False,\n",
    " 'word.istitle()': False,\n",
    " 'word.isdigit()': False,\n",
    " 'postag': 'NNS',\n",
    " 'postag[:2]': 'NN',\n",
    " '-1:word.lower()': 'of',\n",
    " '-1:word.istitle()': False,\n",
    " '-1:word.isupper()': False,\n",
    " '-1:postag': 'IN',\n",
    " '-1:postag[:2]': 'IN',\n",
    " '+1:word.lower()': 'have',\n",
    " '+1:word.istitle()': False,\n",
    " '+1:word.isupper()': False,\n",
    " '+1:postag': 'VBP',\n",
    " '+1:postag[:2]': 'VB'}\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Creating Feature set\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0] #extract word from sentence using index i\n",
    "    postag = sent[i][1] #extract POS tag of word at index i\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(), #lower case word\n",
    "        'word[-3:]': word[-3:], #last 3 characters of word\n",
    "        'word[-2:]': word[-2:], #last 2 characters of word\n",
    "        'word.isupper()': word.isupper(), # is word upper case? \n",
    "        'word.istitle()': word.istitle(), #is the first character of word in upper case?\n",
    "        'word.isdigit()': word.isdigit(), #is it a digit?\n",
    "        'postag': postag, #POS tag of the word\n",
    "        'postag[:2]': postag[:2], #prefix of POS tag\n",
    "    }\n",
    "    if i > 0:\n",
    "        #expanding feature set by including features of previous word if not at the beginning of sentence\n",
    "        word1 = sent[i-1][0] #previous word\n",
    "        postag1 = sent[i-1][1] #POS tag of previous word\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True #specify 'Beginning Of Sentence' if no previous word exists\n",
    "    \n",
    "    #expanding feature set by including features of next word if not at the end of sentence\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })    \n",
    "    else:\n",
    "        features['EOS'] = True #specify 'End Of Sentence' if no previous word exists\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dedfc274",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A sentence is passed as an input. The output is a list of dictionaries that contains features generated for\n",
    "each word within the sentence through the word2features function\n",
    "\n",
    "'''\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "'''\n",
    "Returns an array of labels for each word in the sentence that is passed as input. \n",
    "'''\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e31f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset into features and labels\n",
    "X = [sent2features(s) for s in sentences] #extracting features\n",
    "y = [sent2labels(s) for s in sentences] #extracting labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9cebe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38367\n",
      "38367\n",
      "4796\n",
      "4796\n",
      "4796\n",
      "4796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Split the data into train test and validation data. 80%, 10%, 10%\n",
    "This can be done using the train_test_split function by sklearn. \n",
    "\n",
    "'''\n",
    "\n",
    "# split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "test_size = 0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "\n",
    "print(len(X_train)), print(len(y_train))\n",
    "print(len(X_test)), print(len(y_test))\n",
    "print(len(X_valid)), print(len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d8e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating the CRF Model for NER Tagging. \n",
    "\n",
    "We will be using the LGBFS algorithm (Gradient descent using the L-BFGS method) and it works best using a \n",
    "limited amount of computer memory. It is a popular algorithm for parameter estimation in machine learning. \n",
    "Gradient Descent will be used as an optimization function.\n",
    "\n",
    "'''\n",
    "\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=1,#coefficient for L1 regularization,\n",
    "          c2=1,#coefficients for L2 regularization,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88daa2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions on test data\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "We remove the class O from the labels. This is because it is the NER tag for most of the words within the sentences. \n",
    "We can think of the dataset as being heavily class imbalanced. If 90% of the dataset is class 'O' and our model \n",
    "predicts everything as having class 'O', we have an accuracy of 90% but we have a problem. \n",
    "\n",
    "If we remove class 'O' and evaluate our predictions on the remaining entities, we have a better understanding of\n",
    "how our model performs. \n",
    "\n",
    "It is important to look at Recall and F1 score for a better evaluation as well. \n",
    "\n",
    "'''\n",
    "labels = list(crf.classes_) #defining labels\n",
    "labels.remove('O') #removing class O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddf6ad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Testing Set: \n",
      "Accuracy score:      0.9706208850099526\n",
      "F1 score:          0.843561671750781\n",
      "Recall score:      0.8393217347453353\n"
     ]
    }
   ],
   "source": [
    "#Evaluating on the test set. \n",
    "\n",
    "print(\"For Testing Set: \")\n",
    "print(\"Accuracy score:      {}\".format(metrics.flat_accuracy_score(y_test, y_pred), labels = labels))\n",
    "print(\"F1 score:          {}\".format(metrics.flat_f1_score(y_test, y_pred, average='weighted', labels = labels)))\n",
    "print(\"Recall score:      {}\".format(metrics.flat_recall_score(y_test, y_pred, average='weighted', labels = labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e46eb2f",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13a40ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm='lbfgs',\n",
       "                                 all_possible_transitions=True,\n",
       "                                 max_iterations=100),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff74fc96940>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff6ffefec70>},\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "It is good practice to tune the parameters of the model to obtain the best possible model. \n",
    "The crf model takes the following parameters that we will be tuning:\n",
    "\n",
    "1. c1 : coefficient for L1 regularization\n",
    "2. c2 : coefficient for L2 regularization\n",
    "\n",
    "'''\n",
    "\n",
    "#%%time  #prints time taken to run this block of cell\n",
    "crf_ = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted')\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf_, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=10,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "\n",
    "rs.fit(X_valid, y_valid)\n",
    "#try:\n",
    "#    rs.fit(X_valid, y_valid)\n",
    "#except AttributeError:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40a805be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'c1': 0.5374501506049948, 'c2': 0.011822447399065664}\n",
      "Best CV score: 0.9609731539876526\n",
      "Model size: 0.47M\n"
     ]
    }
   ],
   "source": [
    "#extracting parameters of best model\n",
    "\n",
    "print('Best parameters:', rs.best_params_)\n",
    "print('Best CV score:', rs.best_score_)\n",
    "print('Model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b54719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-training model with best parameters\n",
    "\n",
    "crf_tuned = CRF(algorithm='lbfgs',\n",
    "          c1=0.5374501506049948,#coefficient for L1 regularization,\n",
    "          c2=0.011822447399065664,#coefficients for L2 regularization,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "\n",
    "#training the CRF model on the training set\n",
    "#crf.fit(X_train, y_train)\n",
    "\n",
    "try:\n",
    "    crf_tuned.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6c44fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions on test data\n",
    "\n",
    "y_pred = crf_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "#removing class O NER tags.\n",
    "labels = list(crf_tuned.classes_) #extracting labels\n",
    "labels.remove('O') #removing class O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b747304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Testing Set: \n",
      "Accuracy score:      0.9712140175219024\n",
      "F1 score:          0.8490730261358983\n",
      "Recall score:      0.8468168944711243\n"
     ]
    }
   ],
   "source": [
    "#Evaluating on test data\n",
    "\n",
    "print(\"For Testing Set: \")\n",
    "print(\"Accuracy score:      {}\".format(metrics.flat_accuracy_score(y_test, y_pred), labels = labels))\n",
    "print(\"F1 score:          {}\".format(metrics.flat_f1_score(y_test, y_pred, average='weighted', labels = labels)))\n",
    "print(\"Recall score:      {}\".format(metrics.flat_recall_score(y_test, y_pred, average='weighted', labels = labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
